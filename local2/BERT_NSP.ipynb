{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_NSP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC2Ue2SRZrPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwNK_oEYdx8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertForNextSentencePrediction, BertTokenizer, AdamW\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import string\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ua0Zk67axto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.data = None\n",
        "        with open(path, 'r') as f:\n",
        "            self.data = f.readlines()\n",
        "            self.data = [x.translate(str.maketrans('', '', string.punctuation)) for x in self.data]\n",
        "            self.data = [x for x in self.data if len(x.split())>=2]\n",
        "            self.lengths = [len(y.split()) for y in self.data]\n",
        "            # print(self.lengths)\n",
        "            self.substr_len = 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.lengths[index]\n",
        "        try:\n",
        "            neg_x = self.data[index + 1]\n",
        "            neg_y = self.lengths[index + 1]\n",
        "        except:\n",
        "            neg_x = self.data[index - 1]\n",
        "            neg_y = self.lengths[index - 1]\n",
        "        try:\n",
        "          rand_idx_pos = np.random.randint(0, y - self.substr_len - 1)\n",
        "        except:\n",
        "          rand_idx_pos = np.random.randint(0, y - 1)\n",
        "        try:\n",
        "          rand_idx_neg = np.random.randint(0, neg_y - self.substr_len - 1)\n",
        "        except:\n",
        "          rand_idx_neg = np.random.randint(0, neg_y - 1)\n",
        "        \n",
        "\n",
        "\n",
        "        return x, \\\n",
        "               \" \".join(x.split()[rand_idx_pos:rand_idx_pos + self.substr_len]), \\\n",
        "               \" \".join(neg_x.split()[rand_idx_neg:rand_idx_neg + self.substr_len])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DDVWVrra3li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/DirectedStudy/BERT_NSP/wikitext-2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvvk9r5od5iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = CustomDataset(os.path.join(path, \"train_.txt\"))\n",
        "valid_dataset = CustomDataset(os.path.join(path, \"valid_.txt\"))\n",
        "test_dataset = CustomDataset(os.path.join(path, \"test_.txt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9X6cP_Md8Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBl7AyPBeFT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 4\n",
        "num_workers = 8 if cuda else multiprocessing.cpu_count()\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
        "valid_dataloader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ0F_aDNeILN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model.to(device)\n",
        "lr = 3e-5\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "num_epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14gxTK7feJyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06952aa4-6296-4eaf-aef5-90fb1a7cf415"
      },
      "source": [
        "print(\"len(trainloader): \", len(train_dataloader), \"batch_size: \", batch_size,\n",
        "      \"len(train_dataloader)//batch_size - 1: \", len(train_dataloader) // batch_size - 1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(trainloader):  14952 batch_size:  4 len(train_dataloader)//batch_size - 1:  3737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDAUP3jYeL6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, valid_loader, test_loader, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}:\".format(epoch))\n",
        "        model.train()\n",
        "        num_correct = 0\n",
        "        running_loss = 0.\n",
        "        num_total = 0\n",
        "        label_ids = list()\n",
        "        preds_list = list()\n",
        "        for batch_num, d in enumerate(train_loader):\n",
        "            pos, pos_sub, neg_sub = d[0], d[1], d[2]\n",
        "            # print(pos)\n",
        "            # print(pos_sub)\n",
        "            # print(neg_sub)\n",
        "            labels = torch.cuda.LongTensor(np.zeros((len(pos) * 2), float))\n",
        "            labels[len(pos):] = 1\n",
        "            # print(labels)\n",
        "            labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pairofstrings = list(zip(pos, pos_sub))\n",
        "            pairofstrings.extend(list(zip(pos, neg_sub)))\n",
        "            del pos\n",
        "            del pos_sub\n",
        "            del neg_sub\n",
        "            encoded_batch = tokenizer.batch_encode_plus(pairofstrings, add_special_tokens=True, return_tensors='pt',\n",
        "                                                        return_special_tokens_masks=True, max_length=512,\n",
        "                                                        pad_to_max_length=True)\n",
        "            attention_mask = (encoded_batch['attention_mask'] - encoded_batch['special_tokens_mask']).to(device)\n",
        "            input_ids, token_type_ids = encoded_batch['input_ids'].to(device), encoded_batch['token_type_ids'].to(\n",
        "                device)\n",
        "            loss, logits = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask,\n",
        "                                 next_sentence_label=labels)\n",
        "            # print(logits)\n",
        "            predicted = torch.max(logits, 1)[1]\n",
        "            # predicted = torch.max(logits, 1)[1]\n",
        "            num_total += labels.size(0)\n",
        "            # print(\"predicted:\", predicted)\n",
        "            # print(\"labels:\", labels)\n",
        "            num_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "            batch_size, max_seq_len = input_ids.shape\n",
        "            for b in range(batch_size):\n",
        "                label_ids_temp = []\n",
        "                preds_list_temp = []\n",
        "                for l in range(max_seq_len):\n",
        "                    label_ids_temp.append(labels[b].item())\n",
        "                    preds_list_temp.append(predicted[b].item())\n",
        "                label_ids.append(label_ids_temp.copy())\n",
        "                preds_list.append(preds_list_temp.copy())\n",
        "\n",
        "            del labels\n",
        "            del loss\n",
        "\n",
        "            if batch_num % 100 == 0 or batch_num == len(train_dataloader) // batch_size - 1:\n",
        "                print(\"acc : \", (num_correct) / num_total, \"batch_num:\", batch_num)\n",
        "                torch.save(model.state_dict(), 'model.npy')\n",
        "                torch.save(optimizer.state_dict(), 'optimizer.npy')\n",
        "\n",
        "        print('Train Accuracy: {}'.format(num_correct / num_total),\n",
        "              'Average Train Loss: {}'.format(running_loss / len(train_loader)))\n",
        "        print(\"Precision: \" + str(precision_score(label_ids, preds_list)))\n",
        "        print(\"Recall: \" + str(recall_score(label_ids, preds_list)))\n",
        "        print(\"F1: \" + str(f1_score(label_ids, preds_list)))\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            ep_num = epoch + 1\n",
        "            torch.save(model.state_dict(), 'model' + str(ep_num) + '.npy')\n",
        "            torch.save(optimizer.state_dict(), 'optimizer' + str(ep_num) + '.npy')\n",
        "\n",
        "        model.eval()\n",
        "        num_correct = 0\n",
        "        running_loss = 0.\n",
        "        num_total = 0\n",
        "        with torch.no_grad():\n",
        "            label_ids = list()\n",
        "            preds_list = list()\n",
        "            for batch_num, d in enumerate(valid_loader):\n",
        "                pos, pos_sub, neg_sub = d[0], d[1], d[2]\n",
        "                labels = torch.cuda.LongTensor(np.zeros((len(pos) * 2), float))\n",
        "                labels[len(pos):] = 1\n",
        "                labels.to(device)\n",
        "                pairofstrings = list(zip(pos, pos_sub))\n",
        "                pairofstrings.extend(list(zip(pos, neg_sub)))\n",
        "                del pos\n",
        "                del pos_sub\n",
        "                del neg_sub\n",
        "                encoded_batch = tokenizer.batch_encode_plus(pairofstrings, add_special_tokens=True, return_tensors='pt',\n",
        "                                                            max_length=512, return_special_tokens_masks=True,\n",
        "                                                            pad_to_max_length=True)\n",
        "                attention_mask = (encoded_batch['attention_mask'] - encoded_batch['special_tokens_mask']).to(device)\n",
        "                input_ids, token_type_ids = encoded_batch['input_ids'].to(device), encoded_batch['token_type_ids'].to(\n",
        "                    device)\n",
        "                loss, logits = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask,\n",
        "                                     next_sentence_label=labels)\n",
        "                predicted = torch.max(logits, 1)[1]\n",
        "                # print(\"labels:\")\n",
        "                num_total += labels.size(0)\n",
        "                num_correct += (predicted == labels).sum().item()\n",
        "                running_loss += loss.item()\n",
        "                print(\"predicted, labels:\", predicted.cpu().detach().numpy(), labels.cpu().detach().numpy())\n",
        "                batch_size, max_seq_len = input_ids.shape\n",
        "                for b in range(batch_size):\n",
        "                    label_ids_temp = []\n",
        "                    preds_list_temp = []\n",
        "                    for l in range(max_seq_len):\n",
        "                        label_ids_temp.append(labels[b].item())\n",
        "                        preds_list_temp.append(predicted[b].item())\n",
        "                    label_ids.append(label_ids_temp.copy())\n",
        "                    preds_list.append(preds_list_temp.copy())\n",
        "\n",
        "                del labels\n",
        "                del loss\n",
        "\n",
        "        print('Validation Accuracy: {}'.format(num_correct / num_total),\n",
        "              'Average Validation Loss: {}'.format(running_loss / len(valid_loader)))\n",
        "        print(\"Precision: \" + str(precision_score(label_ids, preds_list)))\n",
        "        print(\"Recall: \" + str(recall_score(label_ids, preds_list)))\n",
        "        print(\"F1: \" + str(f1_score(label_ids, preds_list)))\n",
        "        num_correct = 0\n",
        "        running_loss = 0.\n",
        "        num_total = 0\n",
        "        with torch.no_grad():\n",
        "            label_ids = list()\n",
        "            preds_list = list()\n",
        "            for batch_num, d in enumerate(test_loader):\n",
        "                pos, pos_sub, neg_sub = d[0], d[1], d[2]\n",
        "                labels = torch.cuda.LongTensor(np.zeros((len(pos) * 2), float))\n",
        "                labels[len(pos):] = 1\n",
        "                labels.to(device)\n",
        "                pairofstrings = list(zip(pos, pos_sub))\n",
        "                pairofstrings.extend(list(zip(pos, neg_sub)))\n",
        "                del pos\n",
        "                del pos_sub\n",
        "                del neg_sub\n",
        "                encoded_batch = tokenizer.batch_encode_plus(pairofstrings, add_special_tokens=True, return_tensors='pt',\n",
        "                                                            max_length=512, return_special_tokens_masks=True,\n",
        "                                                            pad_to_max_length=True)\n",
        "                attention_mask = (encoded_batch['attention_mask'] - encoded_batch['special_tokens_mask']).to(device)\n",
        "                input_ids, token_type_ids = encoded_batch['input_ids'].to(device), encoded_batch['token_type_ids'].to(\n",
        "                    device)\n",
        "                loss, logits = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask,\n",
        "                                     next_sentence_label=labels)\n",
        "                predicted = torch.max(logits, 1)[1]\n",
        "                # print(\"labels:\")\n",
        "                num_total += labels.size(0)\n",
        "                num_correct += (predicted == labels).sum().item()\n",
        "                running_loss += loss.item()\n",
        "                batch_size, max_seq_len = input_ids.shape\n",
        "                for b in range(batch_size):\n",
        "                    label_ids_temp = []\n",
        "                    preds_list_temp = []\n",
        "                    for l in range(max_seq_len):\n",
        "                        label_ids_temp.append(labels[b].item())\n",
        "                        preds_list_temp.append(predicted[b].item())\n",
        "                    label_ids.append(label_ids_temp.copy())\n",
        "                    preds_list.append(preds_list_temp.copy())\n",
        "\n",
        "                del labels\n",
        "                del loss\n",
        "        print('Test Accuracy: {}'.format(num_correct / num_total),\n",
        "              'Average Test Loss: {}'.format(running_loss / len(valid_loader)))\n",
        "        print(\"Precision: \" + str(precision_score(label_ids, preds_list)))\n",
        "        print(\"Recall: \" + str(recall_score(label_ids, preds_list)))\n",
        "        print(\"F1: \" + str(f1_score(label_ids, preds_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40m_tSQxipyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5f16103-74dc-4ba1-bfd8-a570054b3244"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY-rFpPReO9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ffb5b2c2-2a40-49e5-ba42-c49b4c52e4d1"
      },
      "source": [
        "train(model, train_dataloader, valid_dataloader, test_dataloader, optimizer, num_epochs)\n",
        "\n",
        "torch.save(model.state_dict(), 'model_final.npy')\n",
        "torch.save(optimizer.state_dict(), 'optimizer_final.npy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:\n",
            "acc :  0.75 batch_num: 0\n",
            "acc :  0.7561881188118812 batch_num: 100\n",
            "acc :  0.8314676616915423 batch_num: 200\n",
            "acc :  0.8538205980066446 batch_num: 300\n",
            "acc :  0.8728179551122195 batch_num: 400\n",
            "acc :  0.8827345309381237 batch_num: 500\n",
            "acc :  0.8930948419301165 batch_num: 600\n",
            "acc :  0.8987161198288159 batch_num: 700\n",
            "acc :  0.9026217228464419 batch_num: 800\n",
            "acc :  0.9049667036625971 batch_num: 900\n",
            "acc :  0.9104645354645354 batch_num: 1000\n",
            "acc :  0.9132606721162579 batch_num: 1100\n",
            "acc :  0.9170482930890924 batch_num: 1200\n",
            "acc :  0.9190046118370484 batch_num: 1300\n",
            "acc :  0.9212169878658102 batch_num: 1400\n",
            "acc :  0.9234676882078614 batch_num: 1500\n",
            "acc :  0.9248126171143035 batch_num: 1600\n",
            "acc :  0.9273956496178718 batch_num: 1700\n",
            "acc :  0.9284425319267073 batch_num: 1800\n",
            "acc :  0.9293739967897271 batch_num: 1868\n",
            "acc :  0.9302340873224618 batch_num: 1900\n",
            "acc :  0.9320964517741129 batch_num: 2000\n",
            "acc :  0.9333650642551166 batch_num: 2100\n",
            "acc :  0.934234438891413 batch_num: 2200\n",
            "acc :  0.9355714906562365 batch_num: 2300\n",
            "acc :  0.9363806747188671 batch_num: 2400\n",
            "acc :  0.9371751299480208 batch_num: 2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_RqKxiuc5oT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFq5VSG2lDej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}